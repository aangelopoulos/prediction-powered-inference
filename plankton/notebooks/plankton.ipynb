{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ebc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.optimize import brentq\n",
    "from scipy.stats import binom\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541f1b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9334570326711781\n"
     ]
    }
   ],
   "source": [
    "# Get data 2006-2014 from the following link: https://darchive.mblwhoilibrary.org/handle/1912/7341\n",
    "# Unzip and merge the datasets in the following directory\n",
    "calib_data = np.load('../calib-outputs.npz')\n",
    "test_data = np.load('../test-outputs.npz')\n",
    "calib_preds = calib_data['preds'].astype(int)\n",
    "calib_labels = calib_data['labels'].astype(int)\n",
    "test_preds = test_data['preds'].astype(int)\n",
    "test_labels = test_data['labels'].astype(int)\n",
    "classes = np.load('../classes.npy')\n",
    "num_classes = classes.shape[0]\n",
    "\n",
    "plankton_classes = np.isin(classes,['mix','mix_elongated','detritus','bad', 'bead', 'bubble', 'other_interaction', 'pollen', 'spore'],invert=True)\n",
    "plankton_classes_list = np.where(plankton_classes)[0]\n",
    "\n",
    "true_count = np.isin(test_labels, plankton_classes_list).sum()\n",
    "uncorrected_est = np.isin(test_preds, plankton_classes_list).sum()\n",
    "print((test_labels == test_preds).astype(float).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a8ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the unique classes \n",
    "calib_uq, calib_uq_counts = np.unique(calib_labels, return_counts=True)\n",
    "calib_uq_freq = calib_uq_counts/calib_uq_counts.sum()\n",
    "calib_uq_sort = np.argsort(calib_uq_freq)[::-1]\n",
    "calib_uq_freq = calib_uq_freq[calib_uq_sort]; calib_uq = calib_uq[calib_uq_sort];\n",
    "calib_uq_cumsum = np.cumsum(calib_uq_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7d91ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mix' 'detritus' 'Leptocylindrus']\n"
     ]
    }
   ],
   "source": [
    "# Problem setup\n",
    "alpha = 0.1\n",
    "delta_1 = 0.1-1e-2\n",
    "delta_2 = 1e-2\n",
    "K = 3\n",
    "nu = plankton_classes.astype(int)\n",
    "nu_trunc = nu[calib_uq]\n",
    "calib_uq = calib_uq[:K]\n",
    "print(classes[calib_uq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283a88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the confusion matrix\n",
    "n = calib_preds.shape[0]\n",
    "N = test_preds.shape[0]\n",
    "\n",
    "C = np.zeros((num_classes,num_classes)).astype(int)\n",
    "for j in range(num_classes):\n",
    "    for l in range(num_classes):\n",
    "        C[j,l] = ((calib_preds == j) & (calib_labels == l)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fb7de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.781e-01 7.389e-02 5.638e-03]\n",
      " [2.194e-02 9.258e-01 2.737e-02]\n",
      " [3.318e-06 3.563e-04 9.670e-01]]\n",
      "[[ 1.024e+00 -8.175e-02 -3.658e-03]\n",
      " [-2.428e-02  1.082e+00 -3.049e-02]\n",
      " [ 5.430e-06 -3.984e-04  1.034e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Construct Ahat\n",
    "Ahat = C[:,calib_uq][calib_uq,:]\n",
    "Ahat = Ahat / Ahat.sum(axis=0)\n",
    "Ahatinv = np.linalg.inv(Ahat)\n",
    "print(np.array_str(Ahat, precision=3))\n",
    "print(np.array_str(Ahatinv, precision=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea124bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78815882 0.13339215 0.0110723 ]\n",
      "[0.79634491 0.12487685 0.01140152]\n",
      "0.011401518499597628\n"
     ]
    }
   ],
   "source": [
    "# Construct the point estimate\n",
    "target_uq, target_uq_counts = np.unique(test_preds, return_counts=True)\n",
    "target_uq_freq = target_uq_counts/target_uq_counts.sum()\n",
    "target_uq_sort = np.argsort(target_uq_freq)[::-1]\n",
    "target_uq_freq = target_uq_freq[target_uq_sort]; target_uq = target_uq[target_uq_sort];\n",
    "target_uq = target_uq[:K]\n",
    "qfhat = target_uq_freq[:K]\n",
    "nu1 = nu_trunc[:K]\n",
    "nu2 = nu_trunc[K:]\n",
    "print(qfhat)\n",
    "print(Ahatinv@qfhat)\n",
    "print(nu1@Ahatinv@qfhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7679425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028894820879305373\n",
      "0.005396558931344003\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Run MAI\n",
    "nmin = int(calib_uq_freq[:K].min()*n)\n",
    "point_estimate = nu1@Ahatinv@qfhat\n",
    "term1 = np.abs(nu1@Ahatinv).sum()*np.sqrt(2/nmin*np.log(2*(K+1)/delta_1))\n",
    "term2 = np.abs(nu1@Ahatinv).sum()*np.sqrt(2/N*np.log(2*(K+1)/delta_1))\n",
    "term3_ub = nu1.max()*alpha\n",
    "term3_lb = nu1.min()*alpha\n",
    "\n",
    "qyhat_ub = np.minimum(point_estimate + term1 + term2 + term3_ub,1)\n",
    "qyhat_lb = np.maximum(point_estimate - term1 - term2 - term3_lb,0)\n",
    "\n",
    "count_plankton_lb = int(binom.ppf(delta_2, N, qyhat_lb))\n",
    "count_plankton_ub = int(binom.ppf(1-delta_2, N, qyhat_ub))\n",
    "\n",
    "print(term1)\n",
    "print(term2)\n",
    "print(term3_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2fde832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rectified confidence interval for the number of plankton observed in 2014 is [0,48526] ([0.0%,14.6%]).\n",
      "The true number of plankton observed in 2014 was 23538 (7.1%), which lies in the interval.\n",
      "The uncorrected estimate was 22068 (6.7%).\n",
      "The corrected estimate was 3760 (1.1%).\n"
     ]
    }
   ],
   "source": [
    "print(f\"The rectified confidence interval for the number of plankton observed in 2014 is [{count_plankton_lb},{count_plankton_ub}] ([{100*qyhat_lb:.1f}%,{100*qyhat_ub:.1f}%]).\")\n",
    "print(f\"The true number of plankton observed in 2014 was {true_count} ({true_count/N*100:.1f}%), which lies in the interval.\")\n",
    "print(f\"The uncorrected estimate was {uncorrected_est} ({uncorrected_est/N*100:.1f}%).\")\n",
    "print(f\"The corrected estimate was {int(N*point_estimate)} ({point_estimate*100:.1f}%).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
