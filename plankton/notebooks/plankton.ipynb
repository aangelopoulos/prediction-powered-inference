{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "52ebc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, copy\n",
    "import sys\n",
    "sys.path.insert(1, '../../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm, binom\n",
    "from scipy.optimize import brentq\n",
    "from concentration import linfty_dkw, linfty_binom, wsr_iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "541f1b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9334570326711781\n"
     ]
    }
   ],
   "source": [
    "# Get data 2006-2014 from the following link: https://darchive.mblwhoilibrary.org/handle/1912/7341\n",
    "# Unzip and merge the datasets in the following directory\n",
    "calib_data = np.load('../calib-outputs.npz')\n",
    "test_data = np.load('../test-outputs.npz')\n",
    "calib_preds = calib_data['preds'].astype(int)\n",
    "calib_labels = calib_data['labels'].astype(int)\n",
    "test_preds = test_data['preds'].astype(int)\n",
    "test_labels = test_data['labels'].astype(int)\n",
    "classes = np.load('../classes.npy')\n",
    "num_classes = classes.shape[0]\n",
    "\n",
    "plankton_classes = np.isin(classes,['mix','mix_elongated','detritus','bad', 'bead', 'bubble', 'other_interaction', 'pollen', 'spore'],invert=True)\n",
    "plankton_classes_list = np.where(plankton_classes)[0]\n",
    "\n",
    "true_count = np.isin(test_labels, plankton_classes_list).sum()\n",
    "uncorrected_est = np.isin(test_preds, plankton_classes_list).sum()\n",
    "print((test_labels == test_preds).astype(float).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f7a8ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the unique classes \n",
    "calib_uq, calib_uq_counts = np.unique(calib_labels, return_counts=True)\n",
    "calib_uq_freq = calib_uq_counts/calib_uq_counts.sum()\n",
    "calib_uq_sort = np.argsort(calib_uq_freq)[::-1]\n",
    "calib_uq_freq = calib_uq_freq[calib_uq_sort]; calib_uq = calib_uq[calib_uq_sort];\n",
    "calib_uq_cumsum = np.cumsum(calib_uq_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7c7d91ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mix' 'detritus' 'Leptocylindrus' 'Chaetoceros' 'mix_elongated' 'dino30'\n",
      " 'Cerataulina' 'Skeletonema' 'Cylindrotheca' 'Guinardia_delicatula']\n"
     ]
    }
   ],
   "source": [
    "# Problem setup\n",
    "alpha = 0.05\n",
    "delta_1 = 0.05-1e-2\n",
    "delta_2 = 1e-2\n",
    "K = 10\n",
    "nu = plankton_classes.astype(int)\n",
    "nu_trunc = nu[calib_uq]\n",
    "calib_uq = calib_uq[:K]\n",
    "print(classes[calib_uq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "283a88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the confusion matrix\n",
    "n = calib_preds.shape[0]\n",
    "N = test_preds.shape[0]\n",
    "\n",
    "C = np.zeros((num_classes,num_classes)).astype(int)\n",
    "for j in range(num_classes):\n",
    "    for l in range(num_classes):\n",
    "        C[j,l] = ((calib_preds == j) & (calib_labels == l)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b1fb7de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.672e-01 7.258e-02 4.598e-03 1.267e-01 4.074e-02 1.410e-01 1.355e-03\n",
      "  2.092e-02 3.830e-03 0.000e+00]\n",
      " [2.170e-02 9.093e-01 2.232e-02 5.128e-02 8.244e-02 2.693e-02 1.716e-01\n",
      "  6.628e-02 1.596e-02 2.885e-03]\n",
      " [3.282e-06 3.499e-04 7.885e-01 6.047e-04 1.072e-01 0.000e+00 1.084e-02\n",
      "  2.142e-02 1.596e-03 6.131e-03]\n",
      " [4.289e-03 9.365e-03 3.831e-04 8.045e-01 1.066e-02 3.591e-04 5.422e-04\n",
      "  5.292e-03 9.575e-04 0.000e+00]\n",
      " [7.646e-04 5.743e-03 1.505e-01 1.282e-02 6.720e-01 0.000e+00 9.894e-02\n",
      "  1.469e-01 5.841e-02 1.442e-03]\n",
      " [5.825e-03 5.146e-04 0.000e+00 1.209e-04 0.000e+00 8.317e-01 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00]\n",
      " [3.282e-06 7.616e-04 2.069e-02 1.209e-04 4.020e-02 0.000e+00 6.996e-01\n",
      "  1.764e-03 0.000e+00 7.212e-04]\n",
      " [9.189e-05 7.616e-04 1.628e-03 2.902e-03 1.039e-02 0.000e+00 4.066e-03\n",
      "  7.369e-01 0.000e+00 0.000e+00]\n",
      " [5.907e-05 4.117e-04 1.916e-03 0.000e+00 1.928e-02 0.000e+00 0.000e+00\n",
      "  0.000e+00 9.192e-01 0.000e+00]\n",
      " [1.641e-05 2.264e-04 9.483e-03 9.675e-04 1.709e-02 0.000e+00 1.301e-02\n",
      "  5.040e-04 0.000e+00 9.888e-01]]\n",
      "[[ 1.037e+00 -8.077e-02  5.739e-03 -1.574e-01 -5.278e-02 -1.731e-01\n",
      "   2.535e-02 -1.076e-02  5.875e-04  2.586e-04]\n",
      " [-2.418e-02  1.103e+00 -2.084e-03 -6.436e-02 -1.158e-01 -3.161e-02\n",
      "  -2.536e-01 -7.433e-02 -1.162e-02 -2.852e-03]\n",
      " [ 1.331e-04  7.719e-04  1.308e+00  2.280e-03 -2.095e-01 -4.854e-05\n",
      "   9.290e-03  3.643e-03  1.103e-02 -7.813e-03]\n",
      " [-5.234e-03 -1.229e-02  3.221e-03  1.245e+00 -1.867e-02  7.475e-04\n",
      "   4.672e-03 -4.070e-03  1.189e-04  3.971e-05]\n",
      " [-8.952e-04 -8.937e-03 -2.903e-01 -2.275e-02  1.556e+00  4.509e-04\n",
      "  -2.116e-01 -3.003e-01 -9.819e-02 -2.899e-04]\n",
      " [-7.250e-03 -1.152e-04 -3.937e-05  9.611e-04  4.440e-04  1.204e+00\n",
      "  -2.134e-05  1.219e-04  3.061e-06 -5.197e-08]\n",
      " [ 7.003e-05 -7.054e-04 -2.200e-02  1.108e-03 -8.300e-02  1.050e-05\n",
      "   1.441e+00  1.379e-02  5.323e-03 -7.919e-04]\n",
      " [-7.182e-05 -9.537e-04  1.313e-03 -4.508e-03 -2.082e-02  4.500e-05\n",
      "  -4.750e-03  1.361e+00  1.342e-03  2.848e-05]\n",
      " [-3.734e-05 -3.031e-04  3.362e-03  5.113e-04 -3.214e-02  1.592e-05\n",
      "   4.530e-03  6.324e-03  1.090e+00  2.362e-05]\n",
      " [ 6.753e-06 -8.246e-05 -7.241e-03 -8.417e-04 -2.374e-02  1.889e-06\n",
      "  -1.534e-02  4.301e-03  1.523e-03  1.011e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Construct Ahat\n",
    "Ahat = C[:,calib_uq][calib_uq,:]\n",
    "Ahat = Ahat / Ahat.sum(axis=0)\n",
    "Ahatinv = np.linalg.inv(Ahat)\n",
    "print(np.array_str(Ahat, precision=3))\n",
    "print(np.array_str(Ahatinv, precision=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7ea124bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78815882 0.13339215 0.0110723  0.00990201 0.00918346 0.00676708\n",
      " 0.00629411 0.00622438 0.00366247 0.00289845]\n",
      "[0.80385235 0.12407735 0.01288754 0.00643702 0.00539448 0.00242871\n",
      " 0.00814223 0.00804347 0.003737   0.0025551 ]\n",
      "0.04423105813425994\n"
     ]
    }
   ],
   "source": [
    "# Construct the point estimate\n",
    "target_uq, target_uq_counts = np.unique(test_preds, return_counts=True)\n",
    "target_uq_freq = target_uq_counts/target_uq_counts.sum()\n",
    "target_uq_sort = np.argsort(target_uq_freq)[::-1]\n",
    "target_uq_freq = target_uq_freq[target_uq_sort]; target_uq = target_uq[target_uq_sort];\n",
    "target_uq = target_uq[:K]\n",
    "qfhat = target_uq_freq[:K]\n",
    "nu1 = nu_trunc[:K]\n",
    "nu2 = nu_trunc[K:]\n",
    "print(qfhat)\n",
    "print(Ahatinv@qfhat)\n",
    "print(nu1@Ahatinv@qfhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7679425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2773\n",
      "0.021913501602999652\n",
      "0.0071864904510905315\n"
     ]
    }
   ],
   "source": [
    "point_estimate = nu1@Ahatinv@qfhat\n",
    "\n",
    "nmin = C[:,calib_uq][calib_uq,:].sum(axis=0).min()\n",
    "\n",
    "theta = 0.99 # The solution to the optimal theta is extreme in this case, so we clip.\n",
    "epsilon1 = max([linfty_binom(C[:,calib_uq][calib_uq,:].sum(axis=0)[k], K, theta*delta_1, Ahat[:,k]) for k in range(K)])\n",
    "epsilon2 = linfty_dkw(N,K,(1-theta)*delta_1)\n",
    "\n",
    "qyhat_lb = np.clip(point_estimate - epsilon1 - epsilon2, 0, 1)\n",
    "qyhat_ub = np.clip(point_estimate + epsilon1 + epsilon2, 0, 1) + alpha\n",
    "\n",
    "count_plankton_lb = int(binom.ppf(delta_2, N, qyhat_lb))\n",
    "count_plankton_ub = int(binom.ppf(1-delta_2, N, qyhat_ub))\n",
    "\n",
    "print(nmin)\n",
    "print(epsilon1)\n",
    "print(epsilon2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e2fde832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rectified confidence interval for the number of plankton observed in 2014 is [4828,41118] ([1.5%,12.3%]).\n",
      "The true number of plankton observed in 2014 was 23538 (7.1%), which lies in the interval.\n",
      "The uncorrected estimate was 22068 (6.7%).\n",
      "The corrected estimate was 14588 (4.4%).\n"
     ]
    }
   ],
   "source": [
    "print(f\"The rectified confidence interval for the number of plankton observed in 2014 is [{count_plankton_lb},{count_plankton_ub}] ([{100*qyhat_lb:.1f}%,{100*qyhat_ub:.1f}%]).\")\n",
    "print(f\"The true number of plankton observed in 2014 was {true_count} ({true_count/N*100:.1f}%), which lies in the interval.\")\n",
    "print(f\"The uncorrected estimate was {uncorrected_est} ({uncorrected_est/N*100:.1f}%).\")\n",
    "print(f\"The corrected estimate was {int(N*point_estimate)} ({point_estimate*100:.1f}%).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
