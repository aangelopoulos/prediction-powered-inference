{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ebc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.optimize import brentq\n",
    "from scipy.stats import binom\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541f1b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421238\n",
      "329832\n"
     ]
    }
   ],
   "source": [
    "# Get data 2006-2014 from the following link: https://darchive.mblwhoilibrary.org/handle/1912/7341\n",
    "# Unzip and merge the datasets in the following directory\n",
    "calib_data = np.load('../calib-outputs.npz')\n",
    "test_data = np.load('../test-outputs.npz')\n",
    "calib_preds = calib_data['preds'].astype(int)\n",
    "calib_labels = calib_data['labels'].astype(int)\n",
    "test_preds = test_data['preds'].astype(int)\n",
    "test_labels = test_data['labels'].astype(int)\n",
    "classes = np.load('../classes.npy')\n",
    "num_classes = classes.shape[0]\n",
    "\n",
    "plankton_classes = np.isin(classes,['mix','mix_elongated','detritus','bad', 'bead', 'bubble', 'other_interaction', 'pollen', 'spore'],invert=True)\n",
    "plankton_classes_list = np.where(plankton_classes)[0]\n",
    "\n",
    "true_count = np.isin(test_labels, plankton_classes_list).sum()\n",
    "uncorrected_est = np.isin(test_preds, plankton_classes_list).sum()\n",
    "print(calib_labels.shape[0])\n",
    "print(test_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a8ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the unique classes \n",
    "calib_uq, calib_uq_counts = np.unique(calib_labels, return_counts=True)\n",
    "calib_uq_freq = calib_uq_counts/calib_uq_counts.sum()\n",
    "calib_uq_sort = np.argsort(calib_uq_freq)[::-1]\n",
    "calib_uq_freq = calib_uq_freq[calib_uq_sort]; calib_uq = calib_uq[calib_uq_sort];\n",
    "calib_uq_cumsum = np.cumsum(calib_uq_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7d91ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "alpha = 0.1\n",
    "delta_1 = 0.1-1e-2\n",
    "delta_2 = 1e-2\n",
    "K = 3\n",
    "nu = plankton_classes.astype(int)\n",
    "nu_trunc = nu[calib_uq]\n",
    "calib_uq = calib_uq[:K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283a88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the confusion matrix\n",
    "n = calib_preds.shape[0]\n",
    "N = test_preds.shape[0]\n",
    "\n",
    "idx_calib_preds_excluded = np.logical_not(np.isin(calib_preds,calib_uq))\n",
    "calib_preds[idx_calib_preds_excluded] = np.random.choice(calib_uq,size=(idx_calib_preds_excluded.sum(),), replace=True,p=calib_uq_freq[:K]/calib_uq_freq[:K].sum())\n",
    "idx_test_preds_excluded = np.logical_not(np.isin(test_preds,calib_uq))\n",
    "test_preds[idx_test_preds_excluded] = np.random.choice(calib_uq, size=(idx_test_preds_excluded.sum(),), replace=True,p=calib_uq_freq[:K]/calib_uq_freq[:K].sum())\n",
    "\n",
    "C = np.zeros((num_classes,num_classes)).astype(int)\n",
    "for j in range(num_classes):\n",
    "    for l in range(num_classes):\n",
    "        C[j,l] = ((calib_preds == j) & (calib_labels == l)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fb7de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.941 0.052 0.007]\n",
      " [0.07  0.916 0.014]\n",
      " [0.03  0.047 0.924]]\n",
      "[[ 1.068 -0.061 -0.007]\n",
      " [-0.081  1.097 -0.016]\n",
      " [-0.03  -0.053  1.084]]\n"
     ]
    }
   ],
   "source": [
    "# Construct Ahat\n",
    "Ahat = C[:,calib_uq][calib_uq,:]\n",
    "Ahat = Ahat / (Ahat.sum(axis=1)[:,None])\n",
    "Ahatinv = np.linalg.inv(Ahat)\n",
    "print(np.array_str(Ahat, precision=3))\n",
    "print(np.array_str(Ahatinv, precision=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea124bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the point estimate\n",
    "target_uq, target_uq_counts = np.unique(test_preds, return_counts=True)\n",
    "target_uq_freq = target_uq_counts/target_uq_counts.sum()\n",
    "target_uq_sort = np.argsort(target_uq_freq)[::-1]\n",
    "target_uq_freq = target_uq_freq[target_uq_sort]; target_uq = target_uq[target_uq_sort];\n",
    "target_uq = target_uq[:K]\n",
    "qfhat = target_uq_freq[:K]\n",
    "nu1 = nu_trunc[:K]\n",
    "nu2 = nu_trunc[K:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7679425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MAI\n",
    "nmin = int(calib_uq_freq[:K].min()*n)\n",
    "point_estimate = nu1@Ahatinv@qfhat\n",
    "term1 = np.abs(nu1@Ahatinv).sum()*np.sqrt(2/nmin*np.log(2*(K+1)/delta_1))\n",
    "term2 = np.abs(nu1@Ahatinv).sum()*np.sqrt(2/N*np.log(2*(K+1)/delta_1))\n",
    "term3 = nu1.max()*alpha\n",
    "\n",
    "qyhat_ub = point_estimate + term1 + term2 + term3\n",
    "qyhat_lb = np.maximum(point_estimate - term1 - term2 - term3,0)\n",
    "\n",
    "count_plankton_lb = int(binom.ppf(delta_2, N, qyhat_lb))\n",
    "count_plankton_ub = int(binom.ppf(1-delta_2, N, qyhat_ub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2fde832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model-assisted confidence interval for the number of plankton observed in 2014 is [0,42841] ([0.0%,12.9%]).\n",
      "The true number of plankton observed in 2014 was 23538 (7.1%), which lies in the interval.\n",
      "The uncorrected estimate was 16975 (5.1%).\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model-assisted confidence interval for the number of plankton observed in 2014 is [{count_plankton_lb},{count_plankton_ub}] ([{100*qyhat_lb:.1f}%,{100*qyhat_ub:.1f}%]).\")\n",
    "print(f\"The true number of plankton observed in 2014 was {true_count} ({true_count/N*100:.1f}%), which lies in the interval.\")\n",
    "print(f\"The uncorrected estimate was {uncorrected_est} ({uncorrected_est/N*100:.1f}%).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
