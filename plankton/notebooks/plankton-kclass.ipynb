{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ebc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, copy\n",
    "import sys\n",
    "sys.path.insert(1, '../../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm, binom\n",
    "from scipy.optimize import brentq\n",
    "from concentration import linfty_dkw, linfty_binom, wsr_iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541f1b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9334570326711781\n"
     ]
    }
   ],
   "source": [
    "# Get data 2006-2014 from the following link: https://darchive.mblwhoilibrary.org/handle/1912/7341\n",
    "# Unzip and merge the datasets in the following directory\n",
    "calib_data = np.load('../calib-outputs.npz')\n",
    "test_data = np.load('../test-outputs.npz')\n",
    "calib_preds = calib_data['preds'].astype(int)\n",
    "calib_labels = calib_data['labels'].astype(int)\n",
    "test_preds = test_data['preds'].astype(int)\n",
    "test_labels = test_data['labels'].astype(int)\n",
    "classes = np.load('../classes.npy')\n",
    "num_classes = classes.shape[0]\n",
    "\n",
    "plankton_classes = np.isin(classes,['mix','mix_elongated','detritus','bad', 'bead', 'bubble', 'other_interaction', 'pollen', 'spore'],invert=True)\n",
    "plankton_idxs = np.where(plankton_classes)[0]\n",
    "\n",
    "true_count = np.isin(test_labels, plankton_idxs).sum()\n",
    "uncorrected_est = np.isin(test_preds, plankton_idxs).sum()\n",
    "print((test_labels == test_preds).astype(float).mean())\n",
    "\n",
    "# Store the class frequencies in the calibration and test sets \n",
    "calib_uq, calib_uq_counts = np.unique(calib_labels, return_counts=True)\n",
    "calib_uq_freq = np.zeros((num_classes,))\n",
    "calib_uq_freq[calib_uq] = calib_uq_counts/calib_labels.shape[0]\n",
    "calib_uq_sort = np.argsort(calib_uq_freq)[::-1]\n",
    "calib_uq_cumsum = np.cumsum(calib_uq_freq[calib_uq_sort])\n",
    "\n",
    "test_pred_uq, test_pred_uq_counts = np.unique(test_preds, return_counts=True)\n",
    "test_pred_uq_freq = np.zeros((num_classes,))\n",
    "test_pred_uq_freq[test_pred_uq] = test_pred_uq_counts/test_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7d91ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mix' 'detritus' 'Leptocylindrus' 'Chaetoceros' 'mix_elongated' 'dino30'\n",
      " 'Cerataulina' 'Skeletonema' 'Cylindrotheca' 'Guinardia_delicatula'\n",
      " 'Rhizosolenia' 'Thalassiosira']\n",
      "0.031884587810216636\n",
      "[1 1 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Problem setup\n",
    "delta_1 = 0.95-1e-3\n",
    "delta_2 = 1e-3\n",
    "K = 12\n",
    "Ical = calib_uq_sort[:K]\n",
    "Icalc = calib_uq_sort[K:]\n",
    "nu = 1-plankton_classes.astype(int)\n",
    "nucal = nu[Ical]\n",
    "nucalc = nu[Icalc]\n",
    "alpha = 1-calib_uq_freq[Ical].sum()\n",
    "print(classes[Ical])\n",
    "print(alpha)\n",
    "print(nucal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283a88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the confusion matrix\n",
    "n = calib_preds.shape[0]\n",
    "N = test_preds.shape[0]\n",
    "\n",
    "C = np.zeros((num_classes,num_classes)).astype(int)\n",
    "for j in range(num_classes):\n",
    "    for l in range(num_classes):\n",
    "        C[j,l] = ((calib_preds == j) & (calib_labels == l)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1fb7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Ahat\n",
    "CIcal2 = C[Ical,:][:,Ical]\n",
    "Ahat = CIcal2 / CIcal2.sum(axis=0)\n",
    "Ahatinv = np.linalg.inv(Ahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea124bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the point estimate\n",
    "qfhatical = test_pred_uq_freq[Ical]\n",
    "point_estimate = nucal@Ahatinv@qfhatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7679425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa/miniconda3/envs/mai/lib/python3.9/site-packages/scipy/stats/_discrete_distns.py:71: RuntimeWarning: divide by zero encountered in _binom_cdf\n",
      "  return _boost._binom_cdf(k, n, p)\n"
     ]
    }
   ],
   "source": [
    "# Do Prediction-Powered Inference\n",
    "nmin = CIcal2.sum(axis=0).min()\n",
    "\n",
    "theta = 0.99 # The solution to the optimal theta is extreme in this case, so we clip.\n",
    "epsilon1 = max([linfty_binom(CIcal2.sum(axis=0)[k], K, theta*delta_1, Ahat[:,k]) for k in range(K)])\n",
    "epsilon2 = linfty_dkw(N,K,(1-theta)*delta_1)\n",
    "\n",
    "lower_constant = alpha * np.abs(np.maximum((nucal@Ahatinv).max(),0) + nucalc.min())\n",
    "upper_constant = alpha * np.abs(np.minimum((nucal@Ahatinv).min(),0) + nucalc.max())\n",
    "\n",
    "qyhat_lb = np.clip(point_estimate - epsilon1 - epsilon2 - lower_constant, 0, 1)\n",
    "qyhat_ub = np.clip(point_estimate + epsilon1 + epsilon2 + upper_constant, 0, 1)\n",
    "\n",
    "count_nonplankton_lb = int(binom.ppf(delta_2, N, qyhat_lb))\n",
    "count_nonplankton_ub = int(binom.ppf(1-delta_2, N, qyhat_ub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fde832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction-powered confidence interval for the number of plankton observed in 2014 is [6769,41729] ([2.1%,12.5%]).\n",
      "The true number of plankton observed in 2014 was 23538 (7.1%), which lies in the interval.\n",
      "The uncorrected estimate was 22068 (6.7%).\n",
      "The corrected estimate was 19515 (5.9%).\n"
     ]
    }
   ],
   "source": [
    "print(f\"The prediction-powered confidence interval for the number of plankton observed in 2014 is [{N-count_nonplankton_ub},{N-count_nonplankton_lb}] ([{100*(1-qyhat_ub):.1f}%,{100*(1-qyhat_lb):.1f}%]).\")\n",
    "print(f\"The true number of plankton observed in 2014 was {true_count} ({true_count/N*100:.1f}%), which lies in the interval.\")\n",
    "print(f\"The uncorrected estimate was {uncorrected_est} ({uncorrected_est/N*100:.1f}%).\")\n",
    "print(f\"The corrected estimate was {int(N*(1-point_estimate))} ({(1-point_estimate)*100:.1f}%).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
