{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "52ebc498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, time, copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from utils import get_train_val_split, get_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "541f1b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data 2006-2014 from the following link: https://darchive.mblwhoilibrary.org/handle/1912/7341\n",
    "# Unzip and merge the datasets in the following directory\n",
    "data_dir = '~/mai_datasets/plankton/2014'\n",
    "model_data_dir = '~/mai_datasets/plankton/merged-2006-2013'\n",
    "model_path = './models/33ckpt.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "76403cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Pct Val\n",
    "pct_val = 0.2\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset, val_dataset = get_train_val_split(model_data_dir, pct_val)\n",
    "test_dataset = get_test_dataset(data_dir)\n",
    "num_classes = len(train_dataset.dataset.classes)\n",
    "model_classes = train_dataset.dataset.classes\n",
    "test_classes = test_dataset.classes\n",
    "\n",
    "# Label correspondence\n",
    "corr = torch.tensor([ train_dataset.dataset.class_to_idx[cls] for cls in test_dataset.classes ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "84da4e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "# Load model\n",
    "print(\"Loading model\")\n",
    "model = tv.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model = model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6763fa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataloaders\n",
    "def collate_fn(batch):\n",
    "  batch = list(filter(lambda x: x is not None, batch))\n",
    "  return torch.utils.data.dataloader.default_collate(batch)\n",
    "num_classes = len(train_dataset.dataset.classes)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5975be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██                                                                                                                                                     | 9/645 [02:24<2:50:28, 16.08s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_preds = torch.zeros((len(test_dataset),num_classes))\n",
    "    test_labels = torch.zeros((len(test_dataset),))\n",
    "    counter = 0\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        imgs, labels = batch\n",
    "        test_preds[counter:counter+labels.shape[0],:] = model(imgs.to(device)).cpu()\n",
    "        test_labels[counter:counter+labels.shape[0]] = labels\n",
    "        counter += labels.shape[0]\n",
    "        if counter > 5000:\n",
    "            break\n",
    "\n",
    "    test_preds = test_preds[:counter]\n",
    "    test_labels = test_labels[:counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "97b0f2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds in this batch: {'Akashiwo': 12, 'Asterionellopsis': 186, 'Bidulphia': 1, 'Chaetoceros_didymus_flagellate': 15, 'Chaetoceros_flagellate': 1, 'Chrysochromulina': 182, 'Cochlodinium': 1, 'Corethron': 5, 'DactFragCerataul': 891, 'Dactyliosolen': 94, 'Delphineis': 1, 'Dictyocha': 988, 'Dinobryon': 106, 'Ditylum': 1, 'Ditylum_parasite': 3, 'Ephemera': 3, 'Euplotes_sp': 1, 'Guinardia_flaccida': 1, 'Guinardia_striata': 112, 'Gyrodinium': 231, 'Hemiaulus': 3, 'Katodinium_or_Torodinium': 777, 'Leptocylindrus': 1, 'Pleuronema_sp': 1, 'Prorocentrum': 110, 'Protoperidinium': 5, 'Pseudochattonella_farcimen': 3, 'Thalassionema': 17, 'Tiarina_fusus': 144, 'amoeba': 20, 'bead': 482, 'detritus': 2, 'dino_large1': 103, 'flagellate_sp3': 6, 'other_interaction': 606, 'pennate': 4, 'spore': 1}\n",
      "\n",
      "Labels in this batch: {'Akashiwo': 1, 'Amphidinium_sp': 66, 'Asterionellopsis': 128, 'Cerataulina': 412, 'Cerataulina_flagellate': 5, 'Ceratium': 6, 'Chaetoceros': 1871, 'Chaetoceros_didymus': 11, 'Chaetoceros_didymus_flagellate': 1, 'Chaetoceros_flagellate': 4, 'Chaetoceros_other': 9, 'Chaetoceros_pennate': 6, 'Chrysochromulina': 48, 'Ciliate_mix': 1074, 'Cochlodinium': 4, 'Corethron': 447, 'Coscinodiscus': 17, 'Cylindrotheca': 1010}\n",
      "\n",
      "Accuracy: 0.0005859375232830644\n"
     ]
    }
   ],
   "source": [
    "uq_preds, counts_preds = np.unique(test_preds.argmax(dim=1).numpy(), return_counts=True)\n",
    "uq_labels, counts_labels = np.unique(test_labels.numpy(), return_counts=True)\n",
    "uq_labels = uq_labels.astype(int)\n",
    "uq_preds = uq_preds.astype(int)\n",
    "\n",
    "print(\"Preds in this batch: \" + str({model_classes[uq_preds[i]] : counts_preds[i] for i in range(uq_preds.shape[0])}))\n",
    "print(\"\")\n",
    "print(\"Labels in this batch: \" + str({test_classes[uq_labels[i]] : counts_labels[i] for i in range(uq_labels.shape[0])}))\n",
    "print(\"\")\n",
    "accuracy = (test_preds.argmax(dim=1) == corr[test_labels.long()]).float().mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b16bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852477b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
