{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca8c82ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy.optimize import brentq\n",
    "from scipy.stats import binom\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "# TODO: put this in another file.\n",
    "def wsr_ci(x,N,delta,grid,num_cpus=10): # x is a [0,1] bounded sequence\n",
    "    n = x.shape[0]\n",
    "    def mu(m,i): return (N*m - np.concatenate([np.array([0,]), np.cumsum(x[:i-1])]))/(N - (np.arange(i)+1) + 1 )\n",
    "    muhats = (1/2 + np.cumsum(x))/(np.arange(n)+1)\n",
    "    sigmahat2s = (1/4 + np.cumsum((x-muhats)**2))/(np.arange(n)+1)\n",
    "    lambdas = np.concatenate([np.array([1,]), np.sqrt(2*np.log(2/delta)/(n*sigmahat2s))[:-1]]) # can't use last entry\n",
    "    def M(m,i): return 1/2*np.maximum(\n",
    "        np.prod(1+np.minimum(lambdas[:i], 1/mu(m,i))*(x[:i]-mu(m,i))),\n",
    "        np.prod(1-np.minimum(lambdas[:i], 1/(1-mu(m,i)))*(x[:i]-mu(m,i)))\n",
    "    )\n",
    "    M = np.vectorize(M)\n",
    "    M_list = Parallel(n_jobs=num_cpus)(delayed(M)(grid,i) for i in range(1,n+1))\n",
    "    ci_indicators = np.prod(np.stack(M_list, axis=1) < 1/delta , axis=1)\n",
    "    return grid[np.where(ci_indicators)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6585a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classification algorithm\n",
    "def find_ellipse(filename, plot):\n",
    "    img_full = cv.imread(filename, cv.IMREAD_COLOR)\n",
    "\n",
    "    cropRows = [-img_full.shape[0]//3, -img_full.shape[0]//6]\n",
    "    cropCols = [-img_full.shape[1]//5, -img_full.shape[1]//15]\n",
    "\n",
    "    img = img_full[cropRows[0]:cropRows[1],cropCols[0]:cropCols[1],:]\n",
    "\n",
    "\n",
    "    # Check if image is loaded fine\n",
    "    if img is None:\n",
    "        print ('Error opening image!')\n",
    "        print ('Usage: hough_circle.py [image_name -- default ' + default_file + '] \\n')\n",
    "\n",
    "\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray = 255-gray\n",
    "\n",
    "    rows = gray.shape[0]\n",
    "\n",
    "    contours,hierarchy = cv.findContours(gray,2,1)\n",
    "    contours_passed = []\n",
    "    fit_ellipses = []\n",
    "    areas = []\n",
    "    area_constraints = [250,1500]\n",
    "    for i in contours:\n",
    "        area = cv.contourArea(i) \n",
    "        if(area >= area_constraints[0] and area <= area_constraints[1]):\n",
    "            contours_passed += [i]\n",
    "            curr_ell = cv.fitEllipse(i)\n",
    "            fit_ellipses += [curr_ell]\n",
    "            areas += [area]\n",
    "    contours_passed, areas = np.array(contours_passed), np.array(areas)\n",
    "    analytic_areas = np.array([ell[1][0]*ell[1][1]*np.pi/4.0 for ell in fit_ellipses])\n",
    "    if areas.shape[0] == 0:\n",
    "        vote = -1\n",
    "    else:\n",
    "        idx_best = np.argmin( np.abs(analytic_areas - areas)/areas )\n",
    "        ell_best = fit_ellipses[idx_best]\n",
    "        decision_boundary = int(img.shape[0]/1.5)\n",
    "        vote = fit_ellipses[idx_best][0][1] >= decision_boundary\n",
    "        if plot:\n",
    "            cv.line(img, (0,decision_boundary), (img.shape[1]-1,decision_boundary), (255,0,0), 2)\n",
    "            cv.ellipse(img, fit_ellipses[idx_best], (0,255,0), -1)\n",
    "\n",
    "    if plot:\n",
    "        img_full[cropRows[0]:cropRows[1],cropCols[0]:cropCols[1],:] = img\n",
    "\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.imshow(img_full)\n",
    "        plt.axis('off');\n",
    "    \n",
    "    return vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7c56dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 78771/78771 [00:00<00:00, 549857.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process .tif images into .png\n",
    "base_path = \"/Users/angelopoulos/Code/working/prediction-powered-inference/ballots/raw/A22_BallotImages\"\n",
    "new_path = \"/Users/angelopoulos/Code/working/prediction-powered-inference/ballots/proc/\"\n",
    "ballot_dirnames = []\n",
    "ballot_filenames = []\n",
    "os.makedirs(new_path, exist_ok = True)\n",
    "counter = 1\n",
    "for dirpath, dirnames, filenames in os.walk(base_path):\n",
    "    for filename in filenames:\n",
    "        if '.tif' in filename:\n",
    "            ballot_dirnames += [dirpath,]\n",
    "            ballot_filenames += [filename,]\n",
    "\n",
    "for i in tqdm(range(len(ballot_filenames))):\n",
    "    if not os.path.exists(new_path + str(counter) + \".png\"):\n",
    "        img_full = cv.imread(ballot_dirnames[i] + \"/\" + ballot_filenames[i], cv.IMREAD_COLOR)\n",
    "        cv.imwrite(new_path + str(counter) + \".png\", img_full)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e44d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/9jh22yw56mj181378_s3p7vr0000gn/T/ipykernel_37901/2661563666.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  contours_passed, areas = np.array(contours_passed), np.array(areas)\n"
     ]
    }
   ],
   "source": [
    "# Read in and clean labels\n",
    "cal_label_csv = pd.read_csv('labels.csv')\n",
    "cal_labeled_image_filenames = [new_path + cal_label_csv['image'][i].split(\"/\")[3] for i in range(len(cal_label_csv))]\n",
    "cal_labels = -np.ones((len(cal_label_csv,)))\n",
    "cal_labels[cal_label_csv['choice'] == \"Matt Haney\"] = 1\n",
    "cal_labels[cal_label_csv['choice'] == \"David Campos\"] = 0\n",
    "\n",
    "cal_preds = np.array([find_ellipse(fname, plot=False) for fname in cal_labeled_image_filenames])\n",
    "clean_cal_preds = cal_preds[(cal_labels >= 0) & (cal_preds >= 0)]\n",
    "clean_cal_labels = cal_labels[(cal_labels >= 0) & (cal_preds >= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b401ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vote Count (0.00% counted): Haney 0 (0.00%), Campos 1 (100.00%), Thrown Out 0 (0.00%)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/9jh22yw56mj181378_s3p7vr0000gn/T/ipykernel_11218/2661563666.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  contours_passed, areas = np.array(contours_passed), np.array(areas)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vote Count (87.47% counted): Haney 41885 (61.28%), Campos 26469 (38.72%), Thrown Out 547 (0.79%)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     vote \u001b[38;5;241m=\u001b[39m \u001b[43mfind_ellipse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mballot_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vote \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     19\u001b[0m         vote_counts[\u001b[38;5;28mint\u001b[39m(vote)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mfind_ellipse\u001b[0;34m(filename, plot)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_ellipse\u001b[39m(filename, plot):\n\u001b[0;32m----> 3\u001b[0m     img_full \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_COLOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     cropRows \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39mimg_full\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39mimg_full\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m6\u001b[39m]\n\u001b[1;32m      6\u001b[0m     cropCols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39mimg_full\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m-\u001b[39mimg_full\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m15\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Do the counting\n",
    "base_path = \"/Users/angelopoulos/Code/working/prediction-powered-inference/ballots/proc/\"\n",
    "plot = False\n",
    "ballot_filenames = []\n",
    "print_rate = 100\n",
    "for dirpath, dirnames, filenames in os.walk(base_path):\n",
    "    for filename in filenames:\n",
    "        if '.png' in filename:\n",
    "            ballot_filenames += [dirpath + \"/\" + filename, ]\n",
    "# Count the prediction-powered votes\n",
    "vote_counts = np.array([0,0,0])\n",
    "for i in range(len(ballot_filenames)):\n",
    "    ballot_filename = ballot_filenames[i]\n",
    "    if ballot_filename in cal_labeled_image_filenames: # Don't count the ones we already labeled\n",
    "        continue\n",
    "    else:\n",
    "        vote = find_ellipse(ballot_filename, plot=plot)\n",
    "        if vote >= 0:\n",
    "            vote_counts[int(vote)] += 1\n",
    "        else:\n",
    "            vote_counts[2] += 1\n",
    "        if i % print_rate == 0:\n",
    "            print(f\"Vote Count ({float(i)/float(len(ballot_filenames))*100:.2f}% counted): Haney {vote_counts[1]} ({vote_counts[1]/(vote_counts[0]+vote_counts[1])*100:.2f}%), Campos {vote_counts[0]} ({100-vote_counts[1]/(vote_counts[0]+vote_counts[1])*100:.2f}%), Thrown Out {vote_counts[2]} ({vote_counts[2]/vote_counts.sum()*100:.2f}%)\", end=\"\\r\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Final Count ({float(i)/float(len(ballot_filenames))*100:.2f}% counted): Haney {vote_counts[1]} ({vote_counts[1]/(vote_counts[0]+vote_counts[1])*100:.2f}%), Campos {vote_counts[0]} ({100-vote_counts[1]/(vote_counts[0]+vote_counts[1])*100:.2f}%), Thrown Out {vote_counts[2]} ({vote_counts[2]/vote_counts.sum()*100:.2f}%)\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "664bd589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction-powered estimate is 62.11%\n",
      "The prediction-powered interval is [62.24%, 64.00%]\n"
     ]
    }
   ],
   "source": [
    "# Run prediction-powered inference\n",
    "delta = 0.05\n",
    "N = 30292 + 47858 # Total number of ballots\n",
    "n = 1000 # Total number of labeled ballots\n",
    "grid = np.linspace(0.3,0.7,1000)\n",
    "vote_counts = np.array([30292, 47858, 621])\n",
    "# Get bounds on confusion matrix for prediction-powered inference\n",
    "rectifier = -(clean_cal_preds.astype(float) - clean_cal_labels.astype(float)).mean() # negative bias\n",
    "pp_est = vote_counts[1]/N + rectifier\n",
    "    \n",
    "ci = 2*wsr_ci((clean_cal_labels - clean_cal_preds + 1)/2, N, delta, grid)-1\n",
    "print(f\"The prediction-powered estimate is {pp_est*100:.2f}%\")\n",
    "print(f\"The prediction-powered interval is [{(pp_est + ci.min())*100:.2f}%, {(pp_est + ci.max())*100:.2f}%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dfc1c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classical interval is [59.11%, 66.44%], ( 415.91% larger)\n"
     ]
    }
   ],
   "source": [
    "# Run classical\n",
    "ci_classical = wsr_ci(clean_cal_labels, N, delta, grid)\n",
    "print(f\"The classical interval is [{ci_classical.min()*100:.2f}%, {ci_classical.max()*100:.2f}%], ({(ci_classical.max() - ci_classical.min())/(ci.max()-ci.min()) * 100 : .2f}% larger)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c83ce4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The imputed-only estimate is 61.24%\n"
     ]
    }
   ],
   "source": [
    "# Imputed-only estimate\n",
    "print(f\"The imputed-only estimate is {vote_counts[1]/N*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475e2607",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             ballot_filenames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [dirpath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m filename, ]\n\u001b[1;32m      8\u001b[0m ballot_filenames \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ballot_filenames)\n\u001b[0;32m----> 9\u001b[0m ballot_filenames \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mballot_filenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m [find_ellipse(ballot_filename, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m ballot_filename \u001b[38;5;129;01min\u001b[39;00m ballot_filenames]\n",
      "File \u001b[0;32mmtrand.pyx:915\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Visualize data\n",
    "base_path = \"/Users/angelopoulos/Code/working/prediction-powered-inference/ballots/proc/\"\n",
    "ballot_filenames = []\n",
    "for dirpath, dirnames, filenames in os.walk(base_path):\n",
    "    for filename in filenames:\n",
    "        if '.png' in filename:\n",
    "            ballot_filenames += [dirpath + \"/\" + filename, ]\n",
    "ballot_filenames = np.array(ballot_filenames)\n",
    "ballot_filenames = np.random.choice(ballot_filenames, 10)\n",
    "[find_ellipse(ballot_filename, plot=True) for ballot_filename in ballot_filenames];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da69de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
